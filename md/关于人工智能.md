# 关于人工智能

## 什么是人工智能

人工智能里面有智能两字，可不代表现在所谓的人工智能真的是智能的。

现在的人工智能是建立在学习上的，被称为机器学习（`machine learning`），或者说是深度学习（`deep learning`） 。比如要识别一只猫，需要有一个由程序员完成的程序来进行学习，然后你就可以提供一张图片，来“让他告诉你这个图片里面有猫吗？”－它给出的结果其实是一个0－1的数字，代表概率，学习的内容就是很多张含有猫的图片－很多很多张，不过对于人类来说，只需要一张猫的图片就能够获得识别出别的图片是不是含有猫的能力。由此可见现在的人工智能很“差劲”。

原因在于人工智能是数学问题，依靠的是概率，而人类依靠的是抽象思维，提供一张白纸，写下一个“2”，人类会告诉你这是一个2（不要说什么鸭子什么之类的简笔画，没有意义），而人工智能会告诉你99.99 %的可能性是2（这个概率值取决于图片，人工智能的模型，训练的数据和数量，要做到很高的识别率也不是很容易），然后是其他。

## 人工智能有危险吗？

很多人想到了电影里的情节，开始害怕人工智能，我认为现在根本不必要担心。

因为这样不也应该担心其他科技吗？像物理，生物，化学不是更危险吗？还有要说的是，很多人以为克隆士兵就像电影里一样，整出来就可以参加战斗，这也太难了吧！更多的是像普通人类一样，出生是个婴儿，既然这样，那这些克隆士兵由国家抚养？开玩笑，直接由公民服兵役不是更好？机器士兵不是更好？

电影多半属于哗众取宠的类型，或者是从事文艺工作者的“天马行空”的幻想。比如影视作品中的机器人认为人类会破坏环境，最终毁灭地球。其实再人类之前已经有很多生物生存，地球经历过多次物种大爆炸，物种大灭绝，现在一般认为恐龙是死于小行星撞地球，这种灾难把恐龙灭绝了，也没见地球发生了什么事。假如人类真的不保护环境，任由部分人去破坏，地球会灭亡吗？不会，无论怎样人类都会比地球先一步灭亡，只要人类灭亡，地球就什么都不用在乎，大不了时间长一点，总会恢复的，反正地球寿命长着呢，人类保护环境，更多的是为人类自己。小学了解到的是核武器的辐射会导致周围的生物无法生存，土地会变得贫瘠，我也不知道这种事是怎么传出来的，美国进行过多次核武器试验，再一些小岛上，但是在那些小岛上，生物并没有消失，照样有生物生存，也没有变得庞大，虽然理论上有可能，但在现实中并未发生。或者说，日本被投放了两个核武器，也没有听说被辐射出来哥斯拉或者什么的，也没有听说那里变成了荒漠，人类面对核武器更多的还是死亡。如果人工智能有能力能够威胁到人类，确连这些这些道理都不懂？

## 有什么方法保证人工智能安全吗？

如果说还是认为人工智能有危险，那有没有方式避免？

有。

现在的人工智能和普通程序一样，都是按照程序员的编写执行，如果能够做新的事情（就是习得新能力），首先需要完成的是让人工智能修改自身的代码，因为计算机是一个“忠诚而且任劳任怨的工具”，只会去执行那些让人乏味的指令，而不会在意一些闲言碎语。既然这样，那就可以有筛选的允许人工智能修改代码的请求，当然人工智能是不能够修改这个筛选功能的部分的（因为发出这个请求也会被阻止掉），这样，人工智能会被永远的限制在这些代码下面，就像压住孙悟空的“五指山”一样（这样唐僧应该就是一个黑客这类破坏网络安全的人了）。

那么这部分如何来完成呢？听起来就挺复杂的。

## 机器人三原则

内容是：
>第零定律：机器人必须保护人类的整体利益不受伤害。\
\
第一定律：机器人不得伤害人类个体，或者目睹人类个体将遭受危险而袖手不管，除非这违反了机器人第零定律。\
\
第二定律：机器人必须服从人给予它的命令，当该命令与第零定律或者第一定律冲突时例外。\
\
第三定律：机器人在不违反第零、第一、第二定律的情况下要尽可能保护自己的生存。

**这个有可能吗？** 我们的筛选程序会按照这个来编写吗？

**基本不可能。这不是逻辑的问题，而是现实的问题。**

### 首先现在的人工智能根本不懂人类语言的意义

比如，使用过翻译软件吧，输入一段话，然后输出一段翻译为其他语言的一句话，翻译的还算可以吧？问题是这个软件是在理解了这句话，才给我的结果吗？不是。那至少理解了语法吧？也不是。问题是太难了，简单的句子还可以，但是人类能够也出来很复杂的句子，怎么办，难道直接说我干不了。所以现在的人工智能是在完成一个概率计算，而不是理解人类的语言（也许是我们让那位老爷子失望了）。

## 如果能够听懂，也不行，现实更复杂

想象一个场景
>一个医疗机器人，发出请求，想要学习武器的使用，目的是为了敌人来时保护自己和伤员，因为只是学习，并未违反那个所谓的定律，同意还是不同意？

**当然是不同意**，因为医疗机器人就是医疗机器人，不需要它有战斗能力，只要能够拯救伤员就够了，如果需要保护，可以派一个士兵机器人跟随而不是自己获得这个能力，而且在真实的战场上，医生和护士也没有拿起武器的。

不让医疗机器人战斗有两个好处

1. 降低复杂度。
2. 安全。复杂度降低自然就会安全。

那这个机器人三原则有什么用？可能有用吧，比如当人类问机器人怎么保护我的安全时，那就回复这个，只不过这和说“hello world”没有什么本质区别，而且还有哗众取宠之嫌。

## 既然机器人三原则不行，那怎么做？

我不知道。

## 你做的再好，有了黑客不就一样不安全吗。是的吗？

也许是吧？难道真人就是百分百安全吗？

人工智能会被攻击，人类也会被洗脑啊？曾经看过一个电视剧，首先是殴打他，他什么都不说，然后开始对他好，就和先抽一嘴巴再给糖吃一样，后来让他杀人甚至是背叛国家都可以。

而且问题的关键点不是应该处理那些黑客吗？我又想起了一个采访，被采访者说的是国人会把黑社会当作崇拜的偶像，同样的，现在的人有把黑客（非网络安全人员）当作崇拜的偶像，这难道不是一种病态心理的表现吗
